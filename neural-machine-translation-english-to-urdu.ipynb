{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10499774,"sourceType":"datasetVersion","datasetId":6500934}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:54.178120Z","iopub.execute_input":"2025-01-20T11:45:54.178454Z","iopub.status.idle":"2025-01-20T11:45:54.192561Z","shell.execute_reply.started":"2025-01-20T11:45:54.178427Z","shell.execute_reply":"2025-01-20T11:45:54.191835Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/english-to-urdu-sentences-with-translation/English to Urdu.csv\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import warnings\nimport pandas as pd\nimport numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense\nimport string  # Add this import to use string.punctuation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:54.554265Z","iopub.execute_input":"2025-01-20T11:45:54.554541Z","iopub.status.idle":"2025-01-20T11:45:54.558863Z","shell.execute_reply.started":"2025-01-20T11:45:54.554520Z","shell.execute_reply":"2025-01-20T11:45:54.557817Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/english-to-urdu-sentences-with-translation/English to Urdu.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:54.833209Z","iopub.execute_input":"2025-01-20T11:45:54.833487Z","iopub.status.idle":"2025-01-20T11:45:54.958491Z","shell.execute_reply.started":"2025-01-20T11:45:54.833466Z","shell.execute_reply":"2025-01-20T11:45:54.957669Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                                          SENTENCES   \\\n0             How can I communicate with my parents?   \n1                           How can I make friends?’   \n2                              Why do I get so sad?’   \n3  If you’ve asked yourself such questions, you’r...   \n4  Depending on where you’ve turned for guidance,...   \n\n                                             MEANING  \n0                 میں اپنے والدین سے کیسے بات کروں ؟  \n1                             میں دوست کیسے بنائوں ؟  \n2                           میں اتنا اداس کیوں ہوں؟.  \n3  اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...  \n4   اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SENTENCES</th>\n      <th>MEANING</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How can I communicate with my parents?</td>\n      <td>میں اپنے والدین سے کیسے بات کروں ؟</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can I make friends?’</td>\n      <td>میں دوست کیسے بنائوں ؟</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do I get so sad?’</td>\n      <td>میں اتنا اداس کیوں ہوں؟.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If you’ve asked yourself such questions, you’r...</td>\n      <td>اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Depending on where you’ve turned for guidance,...</td>\n      <td>اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:54.963327Z","iopub.execute_input":"2025-01-20T11:45:54.963547Z","iopub.status.idle":"2025-01-20T11:45:54.968229Z","shell.execute_reply.started":"2025-01-20T11:45:54.963527Z","shell.execute_reply":"2025-01-20T11:45:54.967498Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"Index(['SENTENCES ', 'MEANING'], dtype='object')"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"df.rename(columns={'SENTENCES ': 'SENTENCES'}, inplace=True)\n\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:55.142675Z","iopub.execute_input":"2025-01-20T11:45:55.143025Z","iopub.status.idle":"2025-01-20T11:45:55.148176Z","shell.execute_reply.started":"2025-01-20T11:45:55.142999Z","shell.execute_reply":"2025-01-20T11:45:55.147271Z"}},"outputs":[{"name":"stdout","text":"Index(['SENTENCES', 'MEANING'], dtype='object')\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"# 1.Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df['SENTENCES'] = df['SENTENCES'].fillna(\"\").astype(str)\ndf['MEANING'] = df['MEANING'].fillna(\"\").astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:58.270628Z","iopub.execute_input":"2025-01-20T11:45:58.270988Z","iopub.status.idle":"2025-01-20T11:45:58.284912Z","shell.execute_reply.started":"2025-01-20T11:45:58.270962Z","shell.execute_reply":"2025-01-20T11:45:58.284055Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":">## Lowercasing and Removing Punctuation\n","metadata":{}},{"cell_type":"code","source":"df['SENTENCES'] = df['SENTENCES'].str.lower().str.translate(str.maketrans('', '', string.punctuation))\ndf['MEANING'] = df['MEANING'].str.translate(str.maketrans('', '', string.punctuation))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:58.599098Z","iopub.execute_input":"2025-01-20T11:45:58.599413Z","iopub.status.idle":"2025-01-20T11:45:58.908272Z","shell.execute_reply.started":"2025-01-20T11:45:58.599386Z","shell.execute_reply":"2025-01-20T11:45:58.907230Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"> ## TOKENIZATION","metadata":{}},{"cell_type":"code","source":"df['SENTENCES'] = df['SENTENCES'].apply(word_tokenize)\ndf['MEANING'] = df['MEANING'].apply(word_tokenize)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:45:58.934609Z","iopub.execute_input":"2025-01-20T11:45:58.934948Z","iopub.status.idle":"2025-01-20T11:46:04.710823Z","shell.execute_reply.started":"2025-01-20T11:45:58.934880Z","shell.execute_reply":"2025-01-20T11:46:04.709767Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:04.712164Z","iopub.execute_input":"2025-01-20T11:46:04.712499Z","iopub.status.idle":"2025-01-20T11:46:04.727316Z","shell.execute_reply.started":"2025-01-20T11:46:04.712474Z","shell.execute_reply":"2025-01-20T11:46:04.726445Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"                                               SENTENCES  \\\n0          [how, can, i, communicate, with, my, parents]   \n1                        [how, can, i, make, friends, ’]   \n2                          [why, do, i, get, so, sad, ’]   \n3      [if, you, ’, ve, asked, yourself, such, questi...   \n4      [depending, on, where, you, ’, ve, turned, for...   \n...                                                  ...   \n30159  [tasty, food, nice, environment, everyone, sho...   \n30160                                       [thumbs, up]   \n30161                               [food, was, awesome]   \n30162  [economical, place, with, a, great, taste, a, ...   \n30163   [food, was, good, but, service, was, very, slow]   \n\n                                                 MEANING  \n0            [میں, اپنے, والدین, سے, کیسے, بات, کروں, ؟]  \n1                           [میں, دوست, کیسے, بنائوں, ؟]  \n2                          [میں, اتنا, اداس, کیوں, ہوں؟]  \n3      [اگر, آپ, نے, اپنے, آپ, سے, ایسے, سوالات, کیے,...  \n4      [اس, بات, پر, منحصر, ہے, کہ, آپ, رہنمائی, کے, ...  \n...                                                  ...  \n30159  [لذیذ, کھانا, اچھا, ماحول, ہر, کسی, کو, دوستوں...  \n30160                                         [بہت, خوب]  \n30161                              [کھانا, لاجواب, تھا۔]  \n30162  [ایک, عظیم, ذائقہ, کے, ساتھ, اقتصادی, جگہ, کرا...  \n30163     [کھانا, اچھا, تھا, لیکن, سروس, بہت, سست, تھی۔]  \n\n[30164 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SENTENCES</th>\n      <th>MEANING</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[how, can, i, communicate, with, my, parents]</td>\n      <td>[میں, اپنے, والدین, سے, کیسے, بات, کروں, ؟]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[how, can, i, make, friends, ’]</td>\n      <td>[میں, دوست, کیسے, بنائوں, ؟]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[why, do, i, get, so, sad, ’]</td>\n      <td>[میں, اتنا, اداس, کیوں, ہوں؟]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[if, you, ’, ve, asked, yourself, such, questi...</td>\n      <td>[اگر, آپ, نے, اپنے, آپ, سے, ایسے, سوالات, کیے,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[depending, on, where, you, ’, ve, turned, for...</td>\n      <td>[اس, بات, پر, منحصر, ہے, کہ, آپ, رہنمائی, کے, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30159</th>\n      <td>[tasty, food, nice, environment, everyone, sho...</td>\n      <td>[لذیذ, کھانا, اچھا, ماحول, ہر, کسی, کو, دوستوں...</td>\n    </tr>\n    <tr>\n      <th>30160</th>\n      <td>[thumbs, up]</td>\n      <td>[بہت, خوب]</td>\n    </tr>\n    <tr>\n      <th>30161</th>\n      <td>[food, was, awesome]</td>\n      <td>[کھانا, لاجواب, تھا۔]</td>\n    </tr>\n    <tr>\n      <th>30162</th>\n      <td>[economical, place, with, a, great, taste, a, ...</td>\n      <td>[ایک, عظیم, ذائقہ, کے, ساتھ, اقتصادی, جگہ, کرا...</td>\n    </tr>\n    <tr>\n      <th>30163</th>\n      <td>[food, was, good, but, service, was, very, slow]</td>\n      <td>[کھانا, اچھا, تھا, لیکن, سروس, بہت, سست, تھی۔]</td>\n    </tr>\n  </tbody>\n</table>\n<p>30164 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":58},{"cell_type":"markdown","source":"> ## Split the datset into test train and cross validation set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:08.423186Z","iopub.execute_input":"2025-01-20T11:46:08.423513Z","iopub.status.idle":"2025-01-20T11:46:08.445413Z","shell.execute_reply.started":"2025-01-20T11:46:08.423486Z","shell.execute_reply":"2025-01-20T11:46:08.444462Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# 2.Vocabulary Creation","metadata":{}},{"cell_type":"markdown","source":">## Build Vocabulary","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nenglish_vocab = {word: idx for idx, (word, _) in enumerate(Counter([w for s in train['SENTENCES'] for w in s]).most_common(10000), start=1)}\nurdu_vocab = {word: idx for idx, (word, _) in enumerate(Counter([w for s in train['MEANING'] for w in s]).most_common(10000), start=1)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:09.002128Z","iopub.execute_input":"2025-01-20T11:46:09.002474Z","iopub.status.idle":"2025-01-20T11:46:09.242367Z","shell.execute_reply.started":"2025-01-20T11:46:09.002446Z","shell.execute_reply":"2025-01-20T11:46:09.241508Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"# 3.Text To Sequence Coversion","metadata":{}},{"cell_type":"code","source":"def text_to_sequence(sentence, vocab):\n    return [vocab.get(word, vocab.get('<unk>', 0)) for word in sentence]\n\ntrain['SENTENCES'] = train['SENTENCES'].apply(lambda x: text_to_sequence(x, english_vocab))\ntrain['MEANING'] = train['MEANING'].apply(lambda x: text_to_sequence(x, urdu_vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:10.870414Z","iopub.execute_input":"2025-01-20T11:46:10.870712Z","iopub.status.idle":"2025-01-20T11:46:11.071686Z","shell.execute_reply.started":"2025-01-20T11:46:10.870688Z","shell.execute_reply":"2025-01-20T11:46:11.070918Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:11.094201Z","iopub.execute_input":"2025-01-20T11:46:11.094430Z","iopub.status.idle":"2025-01-20T11:46:11.109986Z","shell.execute_reply.started":"2025-01-20T11:46:11.094410Z","shell.execute_reply":"2025-01-20T11:46:11.109203Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                               SENTENCES  \\\n7132                  [37, 19, 4, 44, 4141, 9, 34, 1323]   \n25770  [32, 19, 3, 25, 9, 325, 6324, 105, 17, 4142, 2...   \n29908  [35, 377, 377, 67, 802, 1594, 14, 228, 559, 4,...   \n19449                      [29, 19, 10, 2109, 120, 6326]   \n3418                             [238, 25, 13, 112, 551]   \n...                                                  ...   \n29802  [46, 26, 47, 4000, 12, 6199, 459, 406, 83, 400...   \n5390       [20, 134, 38, 0, 97, 98, 1400, 147, 490, 148]   \n860                    [13, 351, 98, 708, 8, 1824, 3, 0]   \n15795           [2, 1, 8825, 667, 27, 148, 6, 550, 3393]   \n23654  [12, 25, 147, 189, 412, 14, 261, 416, 1, 7, 11...   \n\n                                                 MEANING  \n7132                  [19, 25, 135, 1146, 3, 14, 109, 7]  \n25770  [1542, 6602, 3, 22, 25, 50, 3135, 47, 1, 34, 1...  \n29908  [28, 1, 423, 423, 68, 8, 26, 101, 175, 6, 29, ...  \n19449                [1730, 371, 4, 6603, 1, 16, 23, 25]  \n3418                             [31, 494, 5, 316, 5278]  \n...                                                  ...  \n29802  [52, 1, 82, 51, 27, 48, 123, 3, 492, 1, 370, 6...  \n5390   [21, 13, 4, 3369, 10, 22, 79, 396, 39, 21, 124...  \n860                 [31, 701, 1, 16, 2394, 560, 146, 39]  \n15795  [2, 60, 5, 124, 5263, 10, 38, 1005, 4, 4611, 5...  \n23654  [3, 628, 95, 179, 828, 76, 29, 452, 143, 15, 2...  \n\n[24131 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SENTENCES</th>\n      <th>MEANING</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7132</th>\n      <td>[37, 19, 4, 44, 4141, 9, 34, 1323]</td>\n      <td>[19, 25, 135, 1146, 3, 14, 109, 7]</td>\n    </tr>\n    <tr>\n      <th>25770</th>\n      <td>[32, 19, 3, 25, 9, 325, 6324, 105, 17, 4142, 2...</td>\n      <td>[1542, 6602, 3, 22, 25, 50, 3135, 47, 1, 34, 1...</td>\n    </tr>\n    <tr>\n      <th>29908</th>\n      <td>[35, 377, 377, 67, 802, 1594, 14, 228, 559, 4,...</td>\n      <td>[28, 1, 423, 423, 68, 8, 26, 101, 175, 6, 29, ...</td>\n    </tr>\n    <tr>\n      <th>19449</th>\n      <td>[29, 19, 10, 2109, 120, 6326]</td>\n      <td>[1730, 371, 4, 6603, 1, 16, 23, 25]</td>\n    </tr>\n    <tr>\n      <th>3418</th>\n      <td>[238, 25, 13, 112, 551]</td>\n      <td>[31, 494, 5, 316, 5278]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29802</th>\n      <td>[46, 26, 47, 4000, 12, 6199, 459, 406, 83, 400...</td>\n      <td>[52, 1, 82, 51, 27, 48, 123, 3, 492, 1, 370, 6...</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>[20, 134, 38, 0, 97, 98, 1400, 147, 490, 148]</td>\n      <td>[21, 13, 4, 3369, 10, 22, 79, 396, 39, 21, 124...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>[13, 351, 98, 708, 8, 1824, 3, 0]</td>\n      <td>[31, 701, 1, 16, 2394, 560, 146, 39]</td>\n    </tr>\n    <tr>\n      <th>15795</th>\n      <td>[2, 1, 8825, 667, 27, 148, 6, 550, 3393]</td>\n      <td>[2, 60, 5, 124, 5263, 10, 38, 1005, 4, 4611, 5...</td>\n    </tr>\n    <tr>\n      <th>23654</th>\n      <td>[12, 25, 147, 189, 412, 14, 261, 416, 1, 7, 11...</td>\n      <td>[3, 628, 95, 179, 828, 76, 29, 452, 143, 15, 2...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24131 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"print(train.head())\nprint(train['SENTENCES'].iloc[0])\nprint(train['MEANING'].iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:13.429649Z","iopub.execute_input":"2025-01-20T11:46:13.430000Z","iopub.status.idle":"2025-01-20T11:46:13.438745Z","shell.execute_reply.started":"2025-01-20T11:46:13.429971Z","shell.execute_reply":"2025-01-20T11:46:13.437879Z"}},"outputs":[{"name":"stdout","text":"                                               SENTENCES  \\\n7132                  [37, 19, 4, 44, 4141, 9, 34, 1323]   \n25770  [32, 19, 3, 25, 9, 325, 6324, 105, 17, 4142, 2...   \n29908  [35, 377, 377, 67, 802, 1594, 14, 228, 559, 4,...   \n19449                      [29, 19, 10, 2109, 120, 6326]   \n3418                             [238, 25, 13, 112, 551]   \n\n                                                 MEANING  \n7132                  [19, 25, 135, 1146, 3, 14, 109, 7]  \n25770  [1542, 6602, 3, 22, 25, 50, 3135, 47, 1, 34, 1...  \n29908  [28, 1, 423, 423, 68, 8, 26, 101, 175, 6, 29, ...  \n19449                [1730, 371, 4, 6603, 1, 16, 23, 25]  \n3418                             [31, 494, 5, 316, 5278]  \n[37, 19, 4, 44, 4141, 9, 34, 1323]\n[19, 25, 135, 1146, 3, 14, 109, 7]\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import pandas as pd\n\n# Replace 'df' with your dataset variable\ndef clean_data(df):\n    # Ensure columns are correctly named\n    df.rename(columns={'SENTENCES ': 'SENTENCES', 'MEANING ': 'MEANING'}, inplace=True)\n\n    # Replace 'nisc' in lists\n    def clean_column(column):\n        return column.apply(lambda x: [word for word in x if word != 'nisc'])\n\n    df['SENTENCES'] = clean_column(df['SENTENCES'])\n    df['MEANING'] = clean_column(df['MEANING'])\n\n    # Remove rows where SENTENCES or MEANING are empty lists\n    df = df[df['SENTENCES'].apply(bool) & df['MEANING'].apply(bool)]\n    \n    return df\n\n# Apply the cleaning function\ndf = clean_data(df)\n\n# Validate the cleaning process\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:15.931371Z","iopub.execute_input":"2025-01-20T11:46:15.931679Z","iopub.status.idle":"2025-01-20T11:46:16.545207Z","shell.execute_reply.started":"2025-01-20T11:46:15.931653Z","shell.execute_reply":"2025-01-20T11:46:16.544367Z"}},"outputs":[{"name":"stdout","text":"                                           SENTENCES  \\\n0      [how, can, i, communicate, with, my, parents]   \n1                    [how, can, i, make, friends, ’]   \n2                      [why, do, i, get, so, sad, ’]   \n3  [if, you, ’, ve, asked, yourself, such, questi...   \n4  [depending, on, where, you, ’, ve, turned, for...   \n\n                                             MEANING  \n0        [میں, اپنے, والدین, سے, کیسے, بات, کروں, ؟]  \n1                       [میں, دوست, کیسے, بنائوں, ؟]  \n2                      [میں, اتنا, اداس, کیوں, ہوں؟]  \n3  [اگر, آپ, نے, اپنے, آپ, سے, ایسے, سوالات, کیے,...  \n4  [اس, بات, پر, منحصر, ہے, کہ, آپ, رہنمائی, کے, ...  \n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"# 4.Padding Sequences\n>Pad sequences to ensure they have the same length for batch processing","metadata":{}},{"cell_type":"code","source":"max_len_source = max(train['SENTENCES'].apply(len))\nmax_len_target = max(train['MEANING'].apply(len))\n\n\ntrain['SENTENCES'] = pad_sequences(train['SENTENCES'], maxlen=max_len_source, padding='post').tolist()\ntrain['MEANING'] = pad_sequences(train['MEANING'], maxlen=max_len_target, padding='post').tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:47.683430Z","iopub.execute_input":"2025-01-20T11:46:47.683739Z","iopub.status.idle":"2025-01-20T11:46:48.613658Z","shell.execute_reply.started":"2025-01-20T11:46:47.683714Z","shell.execute_reply":"2025-01-20T11:46:48.612879Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"print(train['SENTENCES'].apply(len).unique())\nprint(train['MEANING'].apply(len).unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:48.614812Z","iopub.execute_input":"2025-01-20T11:46:48.615070Z","iopub.status.idle":"2025-01-20T11:46:48.637950Z","shell.execute_reply.started":"2025-01-20T11:46:48.615048Z","shell.execute_reply":"2025-01-20T11:46:48.637089Z"}},"outputs":[{"name":"stdout","text":"[436]\n[923]\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"print(train['SENTENCES'].head())\nprint(train['MEANING'].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T11:46:48.639275Z","iopub.execute_input":"2025-01-20T11:46:48.639508Z","iopub.status.idle":"2025-01-20T11:46:48.661981Z","shell.execute_reply.started":"2025-01-20T11:46:48.639488Z","shell.execute_reply":"2025-01-20T11:46:48.660978Z"}},"outputs":[{"name":"stdout","text":"7132     [37, 19, 4, 44, 4141, 9, 34, 1323, 0, 0, 0, 0,...\n25770    [32, 19, 3, 25, 9, 325, 6324, 105, 17, 4142, 2...\n29908    [35, 377, 377, 67, 802, 1594, 14, 228, 559, 4,...\n19449    [29, 19, 10, 2109, 120, 6326, 0, 0, 0, 0, 0, 0...\n3418     [238, 25, 13, 112, 551, 0, 0, 0, 0, 0, 0, 0, 0...\nName: SENTENCES, dtype: object\n7132     [19, 25, 135, 1146, 3, 14, 109, 7, 0, 0, 0, 0,...\n25770    [1542, 6602, 3, 22, 25, 50, 3135, 47, 1, 34, 1...\n29908    [28, 1, 423, 423, 68, 8, 26, 101, 175, 6, 29, ...\n19449    [1730, 371, 4, 6603, 1, 16, 23, 25, 0, 0, 0, 0...\n3418     [31, 494, 5, 316, 5278, 0, 0, 0, 0, 0, 0, 0, 0...\nName: MEANING, dtype: object\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"# 5.Creating The Model","metadata":{}},{"cell_type":"markdown","source":">## Encoder and Decoder","metadata":{"execution":{"iopub.status.busy":"2025-01-19T14:26:40.898829Z","iopub.execute_input":"2025-01-19T14:26:40.899212Z","iopub.status.idle":"2025-01-19T14:26:40.905357Z","shell.execute_reply.started":"2025-01-19T14:26:40.899182Z","shell.execute_reply":"2025-01-19T14:26:40.903978Z"}}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Reload original train data if necessary\ntrain = df.sample(frac=0.8, random_state=42)  # Example split, replace with your actual split logic\n\n# Fit tokenizers on original text\ntokenizer_source = Tokenizer(num_words=10000, oov_token=\"<unk>\")\ntokenizer_target = Tokenizer(num_words=10000, oov_token=\"<unk>\")\n\ntokenizer_source.fit_on_texts(train['SENTENCES'])\ntokenizer_target.fit_on_texts(train['MEANING'])\n\n# Get vocabulary sizes\nvocab_size_source = len(tokenizer_source.word_index) + 1  # Add 1 for padding token\nvocab_size_target = len(tokenizer_target.word_index) + 1\n\n# Calculate maximum sequence lengths\nmax_encoder_seq_length = max(train['SENTENCES'].apply(len))\nmax_decoder_seq_length = max(train['MEANING'].apply(len))\n\n\n# Convert text to sequences\nencoder_input_data = pad_sequences(tokenizer_source.texts_to_sequences(train['SENTENCES']), \n                                    maxlen=max_encoder_seq_length, padding='post')\n\ndecoder_input_data = pad_sequences(tokenizer_target.texts_to_sequences(train['MEANING'].apply(lambda x: x[:-1])), \n                                    maxlen=max_decoder_seq_length, padding='post')\n\ndecoder_target_data = pad_sequences(tokenizer_target.texts_to_sequences(train['MEANING'].apply(lambda x: x[1:])), \n                                     maxlen=max_decoder_seq_length, padding='post')\n\n# Model parameters\nembedding_dim = 256\nlatent_dim = 512\nvocab_size_source = len(english_vocab) + 1\nvocab_size_target = len(urdu_vocab) + 1\n\n# Encoder\nencoder_inputs = Input(shape=(None,), name=\"encoder_inputs\")\nencoder_embedding = Embedding(vocab_size_source, embedding_dim, mask_zero=True, name=\"encoder_embedding\")(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")\nencoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\nencoder_states = [state_h, state_c]\n\n# Decoder\ndecoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\ndecoder_embedding = Embedding(vocab_size_target, embedding_dim, mask_zero=True, name=\"decoder_embedding\")(decoder_inputs)\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\ndecoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\ndecoder_dense = Dense(vocab_size_target, activation=\"softmax\", name=\"decoder_dense\")\ndecoder_outputs = decoder_dense(decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:11:52.694113Z","iopub.execute_input":"2025-01-20T12:11:52.694418Z","iopub.status.idle":"2025-01-20T12:11:54.274867Z","shell.execute_reply.started":"2025-01-20T12:11:52.694395Z","shell.execute_reply":"2025-01-20T12:11:54.274184Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:11:54.275932Z","iopub.execute_input":"2025-01-20T12:11:54.276174Z","iopub.status.idle":"2025-01-20T12:11:54.281328Z","shell.execute_reply.started":"2025-01-20T12:11:54.276151Z","shell.execute_reply":"2025-01-20T12:11:54.280565Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"from tensorflow.keras.optimizers.schedules import ExponentialDecay\nimport tensorflow as tf\n\n# Set an initial learning rate\ninitial_learning_rate = 0.001\n\n# Set the decay parameters\nlr_schedule = ExponentialDecay(\n    initial_learning_rate=initial_learning_rate,\n    decay_steps=100000,  # Number of steps before learning rate decays\n    decay_rate=0.96,     # Factor by which the learning rate is reduced\n    staircase=True       # If True, the learning rate decays in discrete intervals\n)\n\n# Compile the model with the learning rate schedule and sparse categorical crossentropy loss\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n              loss='sparse_categorical_crossentropy',  # Correct for softmax output and integer labels\n              metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:14:20.907378Z","iopub.execute_input":"2025-01-20T12:14:20.907679Z","iopub.status.idle":"2025-01-20T12:14:20.916678Z","shell.execute_reply.started":"2025-01-20T12:14:20.907657Z","shell.execute_reply":"2025-01-20T12:14:20.915808Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=32,\n    epochs=30,\n    validation_split=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T12:14:23.912426Z","iopub.execute_input":"2025-01-20T12:14:23.912746Z","iopub.status.idle":"2025-01-20T15:38:10.411588Z","shell.execute_reply.started":"2025-01-20T12:14:23.912718Z","shell.execute_reply":"2025-01-20T15:38:10.410610Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 690ms/step - accuracy: 9.3895e-04 - loss: 6.6646 - val_accuracy: 0.0022 - val_loss: 5.3249\nEpoch 2/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 684ms/step - accuracy: 0.0025 - loss: 5.1167 - val_accuracy: 0.0028 - val_loss: 4.8617\nEpoch 3/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 684ms/step - accuracy: 0.0032 - loss: 4.5601 - val_accuracy: 0.0032 - val_loss: 4.6291\nEpoch 4/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 685ms/step - accuracy: 0.0037 - loss: 4.1739 - val_accuracy: 0.0035 - val_loss: 4.4668\nEpoch 5/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 685ms/step - accuracy: 0.0041 - loss: 3.8431 - val_accuracy: 0.0038 - val_loss: 4.3436\nEpoch 6/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 686ms/step - accuracy: 0.0046 - loss: 3.5187 - val_accuracy: 0.0041 - val_loss: 4.2538\nEpoch 7/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 686ms/step - accuracy: 0.0052 - loss: 3.2223 - val_accuracy: 0.0043 - val_loss: 4.2033\nEpoch 8/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 687ms/step - accuracy: 0.0056 - loss: 2.9689 - val_accuracy: 0.0044 - val_loss: 4.1883\nEpoch 9/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 686ms/step - accuracy: 0.0062 - loss: 2.7365 - val_accuracy: 0.0046 - val_loss: 4.1780\nEpoch 10/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 686ms/step - accuracy: 0.0066 - loss: 2.4975 - val_accuracy: 0.0047 - val_loss: 4.1778\nEpoch 11/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 686ms/step - accuracy: 0.0073 - loss: 2.3090 - val_accuracy: 0.0048 - val_loss: 4.1979\nEpoch 12/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 686ms/step - accuracy: 0.0078 - loss: 2.1519 - val_accuracy: 0.0049 - val_loss: 4.2244\nEpoch 13/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 686ms/step - accuracy: 0.0084 - loss: 1.9715 - val_accuracy: 0.0050 - val_loss: 4.2635\nEpoch 14/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0088 - loss: 1.8121 - val_accuracy: 0.0051 - val_loss: 4.2971\nEpoch 15/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0095 - loss: 1.6747 - val_accuracy: 0.0051 - val_loss: 4.3475\nEpoch 16/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 687ms/step - accuracy: 0.0099 - loss: 1.5353 - val_accuracy: 0.0052 - val_loss: 4.3948\nEpoch 17/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 689ms/step - accuracy: 0.0104 - loss: 1.4344 - val_accuracy: 0.0052 - val_loss: 4.4606\nEpoch 18/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 687ms/step - accuracy: 0.0108 - loss: 1.3088 - val_accuracy: 0.0053 - val_loss: 4.5195\nEpoch 19/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 689ms/step - accuracy: 0.0109 - loss: 1.1884 - val_accuracy: 0.0053 - val_loss: 4.5820\nEpoch 20/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0112 - loss: 1.0896 - val_accuracy: 0.0053 - val_loss: 4.6348\nEpoch 21/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 690ms/step - accuracy: 0.0116 - loss: 1.0076 - val_accuracy: 0.0054 - val_loss: 4.7031\nEpoch 22/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0120 - loss: 0.9271 - val_accuracy: 0.0054 - val_loss: 4.7890\nEpoch 23/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 687ms/step - accuracy: 0.0122 - loss: 0.8562 - val_accuracy: 0.0054 - val_loss: 4.8425\nEpoch 24/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0126 - loss: 0.7739 - val_accuracy: 0.0054 - val_loss: 4.9384\nEpoch 25/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 687ms/step - accuracy: 0.0128 - loss: 0.7128 - val_accuracy: 0.0054 - val_loss: 5.0134\nEpoch 26/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 689ms/step - accuracy: 0.0128 - loss: 0.6484 - val_accuracy: 0.0055 - val_loss: 5.0856\nEpoch 27/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 687ms/step - accuracy: 0.0134 - loss: 0.6010 - val_accuracy: 0.0055 - val_loss: 5.1648\nEpoch 28/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 688ms/step - accuracy: 0.0132 - loss: 0.5476 - val_accuracy: 0.0055 - val_loss: 5.2548\nEpoch 29/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 690ms/step - accuracy: 0.0136 - loss: 0.4963 - val_accuracy: 0.0054 - val_loss: 5.3304\nEpoch 30/30\n\u001b[1m593/593\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 690ms/step - accuracy: 0.0142 - loss: 0.4663 - val_accuracy: 0.0055 - val_loss: 5.4129\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('English to Urdu translator(NMT Model).h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T15:38:10.438403Z","iopub.execute_input":"2025-01-20T15:38:10.438675Z","iopub.status.idle":"2025-01-20T15:38:10.697313Z","shell.execute_reply.started":"2025-01-20T15:38:10.438652Z","shell.execute_reply":"2025-01-20T15:38:10.696606Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}